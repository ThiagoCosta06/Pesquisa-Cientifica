{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhancing pests classification through deep learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the libraries \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pytorch_grad_cam'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtimm\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Explainable AI\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpytorch_grad_cam\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m### from pytorch_grad_cam import GradCAM, HiResCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM, FullGrad\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_grad_cam\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GradCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM, FullGrad\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pytorch_grad_cam'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "import platform\n",
    "import sys\n",
    "import argparse\n",
    "import shutil\n",
    "import datetime\n",
    "import glob\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim \n",
    "from torch.optim import lr_scheduler \n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms, models, datasets, utils\n",
    "\n",
    "import timm\n",
    "\n",
    "# Explainable AI\n",
    "import pytorch_grad_cam\n",
    "### from pytorch_grad_cam import GradCAM, HiResCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM, FullGrad\n",
    "from pytorch_grad_cam import GradCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM, FullGrad\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "\n",
    "import wandb    \n",
    "\n",
    "# Local imports\n",
    "from early_stopping import EarlyStopping\n",
    "from models import create_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verificando se está rodando no Colab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "\n",
    "# DEBUG\n",
    "print(f'Running in Colab: {IN_COLAB}')\n",
    "\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuração da GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Configurando GPU...')\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'\\nDevice: {DEVICE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Argument parsing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# Dataset name. ['BreakHis', 'Agricultural Pests Dataset', 'smallopticalsorter']\n",
    "parser.add_argument('--ds', help='Dataset name.', type=str, default='AgriculturalPestsDataSet')\n",
    "# Model architecture [alexnet, vgg, resnet, densenet, squeezenet, (inception), ...]\n",
    "parser.add_argument('--arch', help='CNN architecture', type=str, default='alexnet', )\n",
    "parser.add_argument('--optim', help=\"Hyperparameter optmization: ['none', 'grid', 'random'].\", type=str, default='none', )\n",
    "parser.add_argument('--sm', help='Save the model?', default=True, action='store_true')\n",
    "\n",
    "parser.add_argument('--seed', help='Seed for random number generator.', type=int, default=42)\n",
    "parser.add_argument('--num_workers', help='Number of available cores.', type=int, default=2)\n",
    "parser.add_argument('--debug', help=\"Is running in debug mode?\", required=False, default=False, action='store_true')\n",
    "\n",
    "# Hyperparameters \n",
    "# ---------------\n",
    "parser.add_argument('--bs', help='Barch size.', type=int, default=64)\n",
    "parser.add_argument('--lr', help='Learning rate.', type=float, default=0.0001)\n",
    "parser.add_argument('--mm', help='Momentum.', type=float, default=0.9)\n",
    "parser.add_argument('--ss', help='Step size.', type=int, default=5)\n",
    "### parser.add_argument('--wd', help='Weight decay.', type=float, default=0.1)\n",
    "parser.add_argument('--ep', help='Number of epochs', type=int, default=200) \n",
    "\n",
    "parser.add_argument('--optimizer', help=\"Optimizer. ['SGD', 'Adam'].\", type=str, default='SGD')\n",
    "parser.add_argument('--scheduler', help=\"Scheduler. ['steplr', 'cossine', 'plateau'].\", type=str, default='plateau')\n",
    "\n",
    "# Fine-tunning\n",
    "parser.add_argument('--ft', help='Treinamento com fine-tuning.', default=True, action='store_true')\n",
    "# Data augmentation stretegy. Ignorado quando otimização de hiperparametros\n",
    "parser.add_argument('--da', help='Data augmentation stretegy. 0 = no data augmentation.',  type=int, default=0)\n",
    "# Usa BCELoss em problemas com duas classes. Se False, usa CrossEntropyLoss para qualquer número de classes\n",
    "parser.add_argument('--bce', help='Usa Binary Cross Entropy em problemas com duas classes.', default=True, action='store_true')\n",
    "# Explainable AI\n",
    "parser.add_argument('--xai', help='Perform eXplainable AI analysis.', default=False, action='store_true')\n",
    "\n",
    "# Early stopping\n",
    "parser.add_argument('--es', help='Use early stopping.', default=True, action='store_true')\n",
    "parser.add_argument('--patience', help='Patience for early stopping.', type=int, default=21) # Use 21, if plateau\n",
    "parser.add_argument('--delta', help='Delta for early stopping', type=float, default=0.0001)\n",
    "\n",
    "parser.add_argument('--wandb', type=bool, default=False, action=argparse.BooleanOptionalAction, help='Use wandb.')\n",
    "\n",
    "parser.add_argument('--ec', help='Experiment counter. Used for hp optimization.', type=int, default=0)\n",
    "\n",
    "# Apenas para o BreakHis\n",
    "parser.add_argument('--fold', help='Fold. [1, 2, 3, 4, 5]', type=int, default=1)\n",
    "parser.add_argument('--magnification', help=\"Magnification. ['40X', '100X', '200X', '400X', '']\", type=str, default='')\n",
    "\n",
    "# ***** IMPORTANTE!!! *****\n",
    "# Comentar esta linha após gerar o arquivo .py!\n",
    "# *************************\n",
    "sys.argv = ['-f']\n",
    "\n",
    "# Processa os argumentos informados na linha de comando\n",
    "args = parser.parse_args()\n",
    "\n",
    "# ***** IMPORTANTE!!! *****\n",
    "# Set DEBUG mode:\n",
    "# *************************\n",
    "args.debug = False\n",
    "\n",
    "if args.debug:\n",
    "    args.ep = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if str(DEVICE) != 'cuda':\n",
    "    # Caso não tenha uma GPU compatível disponível, executar apenas para prototipação.\n",
    "    ### args.ep = 2\n",
    "\n",
    "    print('CUDA not availavble. Finishing the program...')\n",
    "    print('\\nDone!\\n\\n')\n",
    "    sys.exit()\n",
    "\n",
    "if args.optim != 'none':\n",
    "    args.sm = False\n",
    "    ### args.da = 0\n",
    "    # if hp optimization, always ignore XAI.\n",
    "    args.xai = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.wandb:\n",
    "    watermark = f'wvc_{args.ds}_{args.arch}_{args.da}'\n",
    "    wandb.init(project=\"wvc-2023-coffee\", name=watermark)\n",
    "    wandb.config.update(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_str = ''\n",
    "for arg in vars(args):\n",
    "    args_str += f'\\n{arg}: {getattr(args, arg)}'\n",
    "    print(f'{arg}: {getattr(args, arg)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_versions():\n",
    "\n",
    "    str = ''\n",
    "    str += f'\\nNumPy: {np.__version__}'\n",
    "    str += f'\\nMatplotlib: {matplotlib.__version__}'\n",
    "    str += f'\\nPandas: {pd.__version__}'\n",
    "    str += f'\\nPIL: {PIL.__version__}'\n",
    "    str += f'\\nScikit-learn: {sklearn.__version__}'\n",
    "    str += f'\\nPyTorch: {torch.__version__}'\n",
    "    str += f'\\nTorchvision: {torchvision.__version__}'\n",
    "\n",
    "    return str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Customizado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageFolderWithPaths(datasets.ImageFolder):\n",
    "    \"\"\" Custom dataset that includes the paths for the image files. \n",
    "    Extends torchvision.datasets.ImageFolder.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    [1] https://gist.github.com/andrewjong/6b02ff237533b3b2c554701fb53d5c4d\n",
    "    [2] https://discuss.pytorch.org/t/dataloader-filenames-in-each-batch/4212/4 \n",
    "    [3] https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\n",
    "    [4] https://pytorch.org/docs/stable/data.html\n",
    "    \"\"\"\n",
    "\n",
    "    # override the __getitem__ method. this is the method that dataloader calls\n",
    "    def __getitem__(self, index):\n",
    "        # this is what ImageFolder normally returns \n",
    "        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n",
    "        \n",
    "        # the image file path\n",
    "        path = self.imgs[index][0]\n",
    "        # make a new tuple that includes original and the path\n",
    "        tuple_with_path = (original_tuple + (path,))\n",
    "        \n",
    "        return tuple_with_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configurating the datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS_PATH_MAIN = 'home/pedro/Datasets/'\n",
    "\n",
    "if args.ds == 'AggriculturalPestsDataSet':\n",
    "    DS_PATH = os.path.join(DS_PATH_MAIN, args.ds, 'AggriculturalPestsDataSet')\n",
    "\n",
    "\n",
    "# DEBUG\n",
    "print(f'Dataset: {args.ds}')\n",
    "print(f'Dataset Path: {DS_PATH}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing the Experiments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pasta principal para armazenar os experimentos\n",
    "EXP_PATH_MAIN = f'exp_{args.ds}'\n",
    "if args.optim != 'none':\n",
    "    EXP_PATH_MAIN = f'exp_hp_{args.ds}'\n",
    "\n",
    "# Cria uma pasta para armazenar os experimentos, caso ainda não exista\n",
    "if not os.path.isdir(EXP_PATH_MAIN):\n",
    "    os.mkdir(EXP_PATH_MAIN)\n",
    "\n",
    "mm_str = f'-mm_{args.mm}' if args.optimizer == 'SGD' else ''\n",
    "\n",
    "ss_str = f'-ss_{args.ss}' if args.scheduler == 'steplr' else ''\n",
    "\n",
    "# String contendo os valores dos hiperparametros deste experimento.\n",
    "hp_str = f'-bs_{args.bs}-lr_{args.lr}-op_{args.optimizer}{mm_str}-sh_{args.scheduler}{ss_str}-epochs_{args.ep}'\n",
    "\n",
    "# Ajusta para o nome da pasta\n",
    "hp_optim = '' if args.optim == 'none' else f'-{args.optim}'\n",
    "\n",
    "str_aux1 = '' if args.ds != 'BreakHis' else f'-mag_{args.magnification}-fold_{str(args.fold)}'\n",
    "\n",
    "# Pasta que ira armazenar os resultados deste treinamento\n",
    "EXP_PATH = os.path.join(EXP_PATH_MAIN, f'({args.ds})-{args.arch}{hp_optim}-da_{args.da}{hp_str}{str_aux1}')\n",
    "print(f'Exp path: {EXP_PATH}')\n",
    "\n",
    "# Check if EXP_PATH exists. If not, create it.\n",
    "### if not glob.glob(EXP_PATH):\n",
    "if not os.path.exists(EXP_PATH):\n",
    "    os.mkdir(EXP_PATH)\n",
    "\n",
    "else:\n",
    "    # If the folder already exists, it is possible the experiment should (or shouldn't) be complete.\n",
    "    # Nós verificamos, observando se o arquivo 'done.txt' está na pasta.\n",
    "    # O arquivo 'done.txt' só é criado quando o experimento terminou por completo.\n",
    "    ### if os.path.exists(os.path.join(EXP_PATH, 'done.txt')):\n",
    "    if os.path.exists(os.path.join(EXP_PATH, 'done.txt')):\n",
    "        # The folder exists and the experiment is done.\n",
    "        print('Experiment already done. Finishing the program...')\n",
    "        print('\\nDone!\\n\\n')\n",
    "        sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(EXP_PATH, 'general_report.txt'), 'w') as model_file:\n",
    "    model_file.write('\\nArguments:')\n",
    "    ### model_file.write(str(args.__str__()))\n",
    "    model_file.write(args_str)\n",
    "    model_file.write('\\n\\nPackage versions:')\n",
    "    model_file.write(str(get_versions()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reprodutibility configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "torch.cuda.manual_seed(args.seed)\n",
    "\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(args.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the dataset\n",
    "------------------------------------------------------------------------\n",
    "Defining the transformations for the data (data augmantation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Média e desvio padrão do ImageNet.\n",
    "DS_MEAN = [0.485, 0.456, 0.406]\n",
    "DS_STD =  [0.229, 0.224, 0.225]\n",
    "\n",
    "# Data transforms \n",
    "# ---------------\n",
    "if args.da == 0:  # Resize(224)\n",
    "    # Treinamento\n",
    "    data_transforms_train = transforms.Compose([\n",
    "        transforms.Resize(size=(224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(DS_MEAN, DS_STD)\n",
    "    ])\n",
    "\n",
    "    # Validacao\n",
    "    data_transforms_val = transforms.Compose([\n",
    "            transforms.Resize(size=(224, 224)), \n",
    "            transforms.ToTensor(), \n",
    "            transforms.Normalize(DS_MEAN, DS_STD)\n",
    "    ])\n",
    "\n",
    "    # Test\n",
    "    data_transform_test = transforms.Compose([\n",
    "            transforms.Resize(size=(224,224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(DS_MEAN, DS_STD)\n",
    "    ])\n",
    "\n",
    "elif args.da == 1: # Resise + CentreCrop (Train = val = test)\n",
    "    # Treinamento\n",
    "    data_transforms_train = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(DS_MEAN, DS_STD)\n",
    "    ])\n",
    "\n",
    "    # Define transformations for validation and test sets\n",
    "    data_transforms_val = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(DS_MEAN, DS_STD),\n",
    "    ])\n",
    "\n",
    "    data_transform_test = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(DS_MEAN, DS_STD),\n",
    "    ])\n",
    "\n",
    "elif args.da == 2: # RandomResizedCrop (224). **** Without DA and HP optmization (WVC'2023) ****\n",
    "    # Treinamento\n",
    "    data_transforms_train = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(DS_MEAN, DS_STD)\n",
    "    ])\n",
    "\n",
    "    # Define transformations for validation and test sets\n",
    "    data_transforms_val = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(DS_MEAN, DS_STD),\n",
    "    ])\n",
    "\n",
    "    data_transform_test = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(DS_MEAN, DS_STD),\n",
    "    ])\n",
    "    \n",
    "elif args.da == 3: # Data augmentation base\n",
    "    # Training\n",
    "    data_transforms_train = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.RandomErasing(p=0.5, scale=(0.02, 0.25)),\n",
    "        transforms.Normalize(DS_MEAN, DS_STD),\n",
    "    ])\n",
    "\n",
    "    # Validation\n",
    "    data_transforms_val = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(DS_MEAN, DS_STD),\n",
    "    ])\n",
    "\n",
    "    # Test\n",
    "    data_transform_test = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(DS_MEAN, DS_STD),\n",
    "    ])\n",
    "\n",
    "elif args.da == 4: # Data augmentation base, No HUE. **** With DA (WVC'2023) ****\n",
    "    # Training\n",
    "    data_transforms_train = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "        ### transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.RandomErasing(p=0.5, scale=(0.02, 0.2)),\n",
    "        transforms.Normalize(DS_MEAN, DS_STD),\n",
    "    ])\n",
    "\n",
    "    # Validation\n",
    "    data_transforms_val = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(DS_MEAN, DS_STD),\n",
    "    ])\n",
    "\n",
    "    # Test\n",
    "    data_transform_test = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(DS_MEAN, DS_STD),\n",
    "    ])\n",
    "\n",
    "elif args.da == 5: # Data augmentation base. No HUE. No RandomErasing.\n",
    "    # Training\n",
    "    data_transforms_train = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "        ### transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        ### transforms.RandomErasing(p=0.5, scale=(0.02, 0.2)),\n",
    "        transforms.Normalize(DS_MEAN, DS_STD),\n",
    "    ])\n",
    "\n",
    "    # Validation\n",
    "    data_transforms_val = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(DS_MEAN, DS_STD),\n",
    "    ])\n",
    "\n",
    "    # Test\n",
    "    data_transform_test = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(DS_MEAN, DS_STD),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets and dataloaders\n",
    "----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treino\n",
    "image_dataset_train = datasets.ImageFolder(os.path.join(DS_PATH, 'train'), data_transforms_train)\n",
    "# Validação\n",
    "image_dataset_val = datasets.ImageFolder(os.path.join(DS_PATH, 'val'), data_transforms_val)\n",
    "\n",
    "# Tamanho dos conjuntos de treino e de validação (número de imagens).\n",
    "train_size = len(image_dataset_train)\n",
    "val_size = len(image_dataset_val)\n",
    "\n",
    "# Nomes e número de classes\n",
    "# -------------------------\n",
    "class_names = image_dataset_train.classes\n",
    "num_classes = len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construindo os Dataloaders\n",
    "dataloader_train = torch.utils.data.DataLoader(image_dataset_train, \n",
    "                                               batch_size=args.bs, \n",
    "                                               num_workers=args.num_workers,\n",
    "                                               shuffle=True,\n",
    "                                              )\n",
    "dataloader_val = torch.utils.data.DataLoader(image_dataset_val,\n",
    "                                             batch_size=args.bs, \n",
    "                                             num_workers=args.num_workers,\n",
    "                                             shuffle=True,\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viewing a batch of images  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_batch(images_batch):\n",
    "    \"\"\" Save one batch of images in a grid.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    * https://discuss.pytorch.org/t/simple-way-to-inverse-transform-normalization/4821/3\n",
    "    * https://pub.towardsai.net/image-classification-using-deep-learning-pytorch-a-case-study-with-flower-image-data-80a18554df63\n",
    "    \"\"\"\n",
    "\n",
    "    # Unnormalize all channels (ImageNet weights)\n",
    "    for t, m, s in zip(images_batch, DS_MEAN, DS_STD):\n",
    "        t.mul_(s).add_(m)\n",
    "        # The normalize code -> t.sub_(m).div_(s)\n",
    "\n",
    "    images_batch_np = images_batch.numpy()\n",
    "    fig_obj = plt.imshow(np.transpose(images_batch_np, (1, 2, 0)))\n",
    "    \n",
    "    # Grava a figura em disco\n",
    "    plt.savefig(os.path.join(EXP_PATH, 'sample_batch.png')) \n",
    "    plt.savefig(os.path.join(EXP_PATH, 'sample_batch.pdf')) \n",
    "    with open(os.path.join(EXP_PATH, 'sample_batch.pickle'),'wb') as file:\n",
    "        pickle.dump(fig_obj, file)\n",
    "\n",
    "items = iter(dataloader_train)\n",
    "image, label = next(items)\n",
    "\n",
    "save_batch(utils.make_grid(image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialing the model\n",
    "----------------------------------------------------------------------------\n",
    "- Models ready for use: \n",
    "    - alexnet\n",
    "    - vgg - Vgg11\n",
    "    - resnet - Resnet18\n",
    "    - resnet50 - Resnet50\n",
    "    - squeezenet\n",
    "    - densenet - Densenet121\n",
    "    - timm_vit - vit_base_patch16_224\n",
    "    - timm_efficientnet - efficientnet_b0\n",
    "    - timm_efficientnet_b2 - efficientnet_b2\n",
    "    - timm_efficientnet_b3 - efficientnet_b3\n",
    "    - timm_mobilenet - convnext_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n>> Inicializando o modelo...')\n",
    "\n",
    "model, input_size, _ = create_model(args.arch, args.ft, num_classes, args.bce)\n",
    "\n",
    "# Envia o modelo para a GPU\n",
    "if DEVICE.type == 'cuda':\n",
    "    model = model.cuda() # Cuda\n",
    "    \n",
    "# Imprime o modelo\n",
    "print(str(model))\n",
    "\n",
    "# Grava a modelo da rede em um arquivo .txt\n",
    "with open(os.path.join(EXP_PATH, 'model.txt'), 'w') as model_file:\n",
    "    model_file.write(str(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss function and optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função de perda\n",
    "if num_classes > 2 or args.bce == False:\n",
    "    # Classificação com mais de duas classes.\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    print('criterion = nn.CrossEntropyLoss()')\n",
    "    \n",
    "else:\n",
    "    # Binary classification:\n",
    "    # ----------------------\n",
    "    # Do not use BCELoss. Instead use BCEWithLogitsLoss.\n",
    "    # https://pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html\n",
    "    # https://discuss.pytorch.org/t/bceloss-vs-bcewithlogitsloss/33586/21\n",
    "    ### criterion = nn.BCELoss()\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    print('criterion = nn.BCEWithLogitsLoss()')\n",
    "\n",
    "# Otimizador\n",
    "if args.optimizer == 'SGD':\n",
    "    optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.mm)\n",
    "\n",
    "elif args.optimizer == 'Adam':\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scheduler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.scheduler == 'plateau':\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, )\n",
    "    print(scheduler)\n",
    "\n",
    "elif args.scheduler == 'cossine':\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, \n",
    "                                                           T_max=len(dataloader_train), \n",
    "                                                           eta_min=0,\n",
    "                                                           last_epoch=-1)\n",
    "    print(scheduler)\n",
    "\n",
    "elif args.scheduler ==  'steplr':\n",
    "\n",
    "    # Step size of the learning rate\n",
    "    if args.ss != 0:\n",
    "        # https://pytorch.org/docs/stable/_modules/torch/optim/lr_scheduler.html#StepLR\n",
    "        scheduler = lr_scheduler.StepLR(optimizer, step_size=args.ss)\n",
    "        print(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(criterion)\n",
    "print(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.wandb:   \n",
    "    wandb.watch(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n>> Training the model...')\n",
    "\n",
    "# Tempo total do treinamento (treinamento e validação)\n",
    "time_total_start = time.time()\n",
    "\n",
    "# Lista das perdas (loss) e acurácias (accuracy) de trino para cada época.\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "\n",
    "# Lista das perdas (loss) e acurácias (accuracy) de validação para cada época.\n",
    "val_loss_list = []\n",
    "val_acc_list = []\n",
    "\n",
    "lr_list = []\n",
    "\n",
    "if args.es:\n",
    "    early_stopping = EarlyStopping(patience=args.patience, delta=args.delta)\n",
    "\n",
    "for epoch in range(args.ep):\n",
    "    # =========================================================================\n",
    "    # TRAINING\n",
    "    # =========================================================================\n",
    "    # Inicia contagem de tempo deste época\n",
    "    time_epoch_start = time.time()\n",
    "\n",
    "    # Perdas (loss) nesta época\n",
    "    train_loss_epoch = 0.\n",
    "    # Número de amostras classificadas corretamente nesta época\n",
    "    train_num_hits_epoch = 0  \n",
    "\n",
    "    # Habilita o modelo para o modo de treino \n",
    "    model.train() \n",
    "\n",
    "    # Iterate along the batches of the TRAINING SET\n",
    "    # ---------------------------------------------\n",
    "    for i, (inputs, labels) in enumerate(dataloader_train):\n",
    "\n",
    "        if DEVICE.type == 'cuda':\n",
    "            inputs = inputs.to(DEVICE) \n",
    "            labels = labels.to(DEVICE) \n",
    "\n",
    "        # Zera os parametros do gradiente\n",
    "        optimizer.zero_grad() \n",
    "\n",
    "        # FORWARD\n",
    "        # ------>\n",
    "        # Habilita o cálculo do gradiente\n",
    "        torch.set_grad_enabled(True) \n",
    "\n",
    "        # Gera a saida a partir da entrada\n",
    "        outputs = model(inputs) \n",
    "\n",
    "        if num_classes == 2 and args.bce:\n",
    "            # Calculate probabilities\n",
    "            # https://discuss.pytorch.org/t/bceloss-vs-bcewithlogitsloss/33586/27\n",
    "            outputs_prob = torch.sigmoid(outputs) \n",
    "            preds = (outputs_prob > 0.5).float().squeeze()\n",
    "\n",
    "            # Calcula a perda (loss)\n",
    "            loss = criterion(outputs.squeeze(), labels.float())\n",
    "\n",
    "        else:\n",
    "            # 'outputs' estão em porcentagens. Tomar os maximos como a respostas.\n",
    "            # Ex: batch=3 com 2 classes, entao preds = [1, 0, 1]\n",
    "            preds = torch.argmax(outputs, dim=1).float() \n",
    "\n",
    "            # Calcula a perda (loss)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        # BACKWARD\n",
    "        # <-------\n",
    "        loss.backward() \n",
    "\n",
    "        # Atualiza o gradiente \n",
    "        optimizer.step()\n",
    "\n",
    "        # Atualiza o loss da época\n",
    "        train_loss_epoch += float(loss.item()) * inputs.size(0) \n",
    "\n",
    "        # Atualiza o número de amostras classificadas corretamente nessa época.\n",
    "        train_num_hits_epoch += torch.sum(preds == labels.data) \n",
    "\n",
    "    train_loss_epoch /= len(image_dataset_train)\n",
    "    train_acc_epoch = float(train_num_hits_epoch.double() / len(image_dataset_train))\n",
    "\n",
    "    # Store loss and accuracy in lists\n",
    "    train_loss_list.append(train_loss_epoch)\n",
    "    train_acc_list.append(train_acc_epoch)\n",
    "\n",
    "    # =========================================================================\n",
    "    # VALIDATION\n",
    "    # =========================================================================\n",
    "    model.eval() \n",
    "\n",
    "    # Pego o numero de perda e o numero de acertos\n",
    "    val_loss_epoch = 0. # Atual perda\n",
    "    val_num_hits_epoch = 0 # Numero de itens corretos\n",
    "    \n",
    "    # Iterate along the batches of the VALIDATION SET\n",
    "    # -----------------------------------------------\n",
    "    for i, (inputs, labels) in enumerate(dataloader_val):\n",
    "\n",
    "        if DEVICE.type == 'cuda':\n",
    "            inputs = inputs.to(DEVICE)\n",
    "            labels = labels.to(DEVICE)\n",
    "\n",
    "        # Zero o gradiente antes do calculo do loss\n",
    "        optimizer.zero_grad() \n",
    "\n",
    "        # Desabilita o gradiente, pois os parametros nao podem mudar durante etapa de validacao\n",
    "        torch.set_grad_enabled(False) \n",
    "\n",
    "        # Gero um tensor cujas linhas representam o tamanho do \"batch\" do input\n",
    "        outputs = model(inputs) \n",
    "\n",
    "        if num_classes == 2 and args.bce:\n",
    "            # Calculate probabilities\n",
    "            # https://discuss.pytorch.org/t/bceloss-vs-bcewithlogitsloss/33586/27\n",
    "            outputs_prob = torch.sigmoid(outputs) \n",
    "            preds = ((outputs_prob > 0.5).float()).squeeze()\n",
    "\n",
    "            # Calcula a perda (loss)\n",
    "            loss = criterion(outputs.squeeze(), labels.float())\n",
    "\n",
    "        else:\n",
    "            # Retorna a maior predicao.\n",
    "            preds = torch.argmax(outputs, dim=1).float()\n",
    "\n",
    "            # Calcula a perda (loss)\n",
    "            loss = criterion(outputs, labels) \n",
    "\n",
    "        # Loss acumulado na época\n",
    "        val_loss_epoch += float(loss.item()) * inputs.size(0)\n",
    "\n",
    "        # Acertos acumulados na época\n",
    "        val_num_hits_epoch += torch.sum(preds == labels.data)\n",
    "\n",
    "    # Ajusta o learning rate\n",
    "    if args.scheduler == 'steplr' and args.ss != 0:\n",
    "        scheduler.step() \n",
    "    \n",
    "    elif args.scheduler == 'cossine' and epoch >= 10:\n",
    "        scheduler.step()\n",
    "\n",
    "    elif args.scheduler == 'plateau':\n",
    "        scheduler.step(val_loss_epoch)\n",
    "\n",
    "    lr_epoch = optimizer.param_groups[0]['lr']\n",
    "    lr_list.append(lr_epoch)\n",
    "        \n",
    "    # Calculo a perda e acuracia de todo o conjunto de validacao\n",
    "    val_loss_epoch /= len(image_dataset_val)\n",
    "    val_acc_epoch = float(val_num_hits_epoch.double() / len(image_dataset_val))\n",
    "\n",
    "    # Inserindo a perda e acuracia para os arrays \n",
    "    val_loss_list.append(val_loss_epoch)\n",
    "    val_acc_list.append(val_acc_epoch)\n",
    "\n",
    "    if args.es:\n",
    "        early_stopping(val_loss_epoch, model, epoch)\n",
    "        \n",
    "        if early_stopping.early_stop:\n",
    "            print(f'Early stopping in epoch {early_stopping.best_epoch}!')\n",
    "            break\n",
    "\n",
    "    # Calculo de tempo total da época\n",
    "    time_epoch = time.time() - time_epoch_start\n",
    "    \n",
    "    # PRINTING\n",
    "    # --------\n",
    "    print(f'Epoch {epoch}/{args.ep - 1} - TRAIN Loss: {train_loss_epoch:.4f} VAL. Loss: {val_loss_epoch:.4f} - TRAIN Acc: {train_acc_epoch:.4f} VAL. Acc: {val_acc_epoch:.4f} ({time_epoch:.4f} seconds)')\n",
    "\n",
    "    if args.wandb:   \n",
    "        wandb.log({'epoch': epoch, 'train_loss': train_loss_epoch, 'val_loss': val_loss_epoch, 'train_acc': train_acc_epoch,'val_acc': val_acc_epoch,'epoch_time': time_epoch})\n",
    "\n",
    "# Calcula do tempo total do treinamento (treinamento e validação)\n",
    "time_total_train = time.time() - time_total_start\n",
    "\n",
    "# PRINTING\n",
    "print('Treinamento finalizado. ({0}m {1}s)'.format(int(time_total_train // 60), int(time_total_train % 60)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.es:\n",
    "    # load the last checkpoint with the best model\n",
    "    model.load_state_dict(torch.load('checkpoint.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "if args.sm:\n",
    "    model_file = os.path.join(EXP_PATH, 'model.pth')\n",
    "    torch.save(model, model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysing the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista com os indices das épocas. [0, 1, ... num_epochs - 1]\n",
    "epochs_list = []\n",
    "for i in range(len(train_loss_list)):\n",
    "    epochs_list.append(i)\n",
    "\n",
    "# Plot - Loss \n",
    "# -----------\n",
    "fig_obj = plt.figure()\n",
    "\n",
    "plt.title('Loss')\n",
    "plt.plot(epochs_list, train_loss_list, c='magenta', label='Train loss', fillstyle='none')\n",
    "plt.plot(epochs_list, val_loss_list, c='green', label='Val. loss', fillstyle='none')\n",
    "if args.es:\n",
    "    plt.axvline(x=early_stopping.best_epoch, color='r', label='Early stopping')\n",
    "    ### plt.text(early_stopping.best_epoch + 0.1, (-early_stopping.best_score) + .05, str(f'{-early_stopping.best_score:.4f}'), color = 'blue', fontweight = 'bold')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "# Grava a figura em disco\n",
    "plt.savefig(os.path.join(EXP_PATH, 'chart_loss.png'))\n",
    "plt.savefig(os.path.join(EXP_PATH, 'chart_loss.pdf')) \n",
    "with open(os.path.join(EXP_PATH, 'chart_loss.pickle'),'wb') as file:\n",
    "    pickle.dump(fig_obj, file)\n",
    "\n",
    "# Plot - Accuracy\n",
    "# ---------------\n",
    "fig_obj = plt.figure()\n",
    "\n",
    "plt.title('Accuracy')\n",
    "plt.plot(epochs_list, train_acc_list, c='magenta', label='Train accuracy', fillstyle='none')\n",
    "plt.plot(epochs_list, val_acc_list, c='green', label='Val. accuracy', fillstyle='none')\n",
    "if args.es:\n",
    "    plt.axvline(x=early_stopping.best_epoch, color='r', label='Early stopping')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "# Grava a figura em disco\n",
    "plt.savefig(os.path.join(EXP_PATH, 'chart_acc.png')) \n",
    "plt.savefig(os.path.join(EXP_PATH, 'chart_acc.pdf')) \n",
    "with open(os.path.join(EXP_PATH, 'chart_acc.pickle'),'wb') as file:\n",
    "    pickle.dump(fig_obj, file)\n",
    "\n",
    "# Plot LR\n",
    "# ---------------\n",
    "fig_obj = plt.figure()\n",
    "\n",
    "plt.title('LR')\n",
    "plt.plot(epochs_list, lr_list, c='magenta', label='LR', fillstyle='none')\n",
    "if args.es:\n",
    "    plt.axvline(x=early_stopping.best_epoch, color='r', label='Early stopping')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('LR')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "# Grava a figura em disco\n",
    "plt.savefig(os.path.join(EXP_PATH, 'chart_lr.png')) \n",
    "plt.savefig(os.path.join(EXP_PATH, 'chart_lr.pdf')) \n",
    "with open(os.path.join(EXP_PATH, 'chart_lr.pickle'),'wb') as file:\n",
    "    pickle.dump(fig_obj, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the trainning report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arquivo CSV que irá armazenar todos os losses e acuracias.\n",
    "report_filename = os.path.join(EXP_PATH, 'training_report' + '.csv')\n",
    "\n",
    "# Cria o arquivo CSV\n",
    "report_file = open(report_filename, 'w')\n",
    "\n",
    "header = 'Epoch\\tTrain Loss\\tVal. Loss\\tTrain Acc.\\tVal. Acc.\\n'\n",
    "report_file.write(header)\n",
    "\n",
    "# Putting values from each epoch inside of archive\n",
    "for i in range(0, len(train_loss_list)):\n",
    "    text = str(i) + '\\t' + str(train_loss_list[i]) + '\\t' + str(val_loss_list[i]) + '\\t' + str(train_acc_list[i]) + '\\t' + str(val_acc_list[i]) + '\\t' + str(lr_list[i]) \n",
    "    if args.es and i == early_stopping.best_epoch:\n",
    "        text += '\\t *\\n'\n",
    "    else:\n",
    "        text += '\\n'\n",
    "\n",
    "    report_file.write(text)\n",
    "\n",
    "if args.es:\n",
    "    report_file.write(f'Early stopping: \\t {early_stopping.best_epoch}')\n",
    "\n",
    "# Closing\n",
    "report_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets\n",
    "# ---------\n",
    "img_dataset_test =  ImageFolderWithPaths(os.path.join(DS_PATH, 'test'), data_transform_test)\n",
    "\n",
    "img_dataset_val =  ImageFolderWithPaths(os.path.join(DS_PATH, 'val'), data_transform_test)\n",
    "\n",
    "# DataLoaders\n",
    "# -----------\n",
    "dataloader_test = torch.utils.data.DataLoader(img_dataset_test, \n",
    "                                              batch_size=args.bs,  \n",
    "                                              num_workers=args.num_workers,\n",
    "                                              shuffle=False,\n",
    "                                             )\n",
    "\n",
    "dataloader_val  = torch.utils.data.DataLoader(img_dataset_val,\n",
    "                                              batch_size=args.bs,\n",
    "                                              num_workers=args.num_workers,\n",
    "                                              shuffle=False, \n",
    "                                             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Habilita o modelo para avaliação\n",
    "model.eval()\n",
    "\n",
    "# Listas contendo as classes reais (true_test), as classes preditas pelo modelo ('pred_test') e\n",
    "# os caminhos para cada imagem. Apenas para o conjunto de testes.\n",
    "true_test_list = []\n",
    "pred_test_list = []\n",
    "path_test_list = []\n",
    "\n",
    "prob_test_list = []\n",
    "\n",
    "# Inicia a contagem do tempo apenas para teste\n",
    "time_test_start = time.time()\n",
    "\n",
    "# Itera sobre o dataloader_test\n",
    "# -----------------------------\n",
    "for i, (img_list, true_list, path_list) in enumerate(dataloader_test):\n",
    "\n",
    "    if DEVICE.type == 'cuda':\n",
    "        # Cuda extension\n",
    "        img_list = img_list.to(DEVICE)\n",
    "        true_list = true_list.to(DEVICE)\n",
    "\n",
    "    # Para que o gradiente nao se atualize!\n",
    "    torch.set_grad_enabled(False)\n",
    "\n",
    "    outputs = model(img_list)\n",
    "\n",
    "    if num_classes == 2 and args.bce:\n",
    "        # Calculate probabilities\n",
    "        # https://discuss.pytorch.org/t/bceloss-vs-bcewithlogitsloss/33586/27\n",
    "        outputs_prob = torch.sigmoid(outputs) \n",
    "        preds = (outputs_prob > 0.5).float().squeeze()\n",
    "\n",
    "        prob_test_batch = np.asarray(outputs_prob.cpu())\n",
    "\n",
    "        # Temos a probabilidade só da classe 1. \n",
    "        # Probability of class 0 is (1 - prob(c_1))\n",
    "        prob_test_batch = np.c_[1. - prob_test_batch, prob_test_batch]\n",
    "\n",
    "    else:\n",
    "        ### _, preds = torch.max(output, dim=1)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "\n",
    "        # https://discuss.pytorch.org/t/obtain-probabilities-from-cross-entropy-loss/157259\n",
    "        outputs_prob = nn.functional.softmax(outputs, dim=1)\n",
    "\n",
    "        prob_test_batch = np.asarray(outputs_prob.cpu())\n",
    "\n",
    "    if DEVICE.type == 'cuda':\n",
    "        # Lista de labels com a resposta (batch with 128 samples)\n",
    "        true_test_batch = np.asarray(true_list.cpu())\n",
    "        # Lista de labels com a predicao (batch with 128 samples)\n",
    "        pred_test_batch = np.asarray(preds.cpu())\n",
    "\n",
    "    else:\n",
    "        true_test_batch = np.asarray(true_list)\n",
    "        pred_test_batch = np.asarray(preds)\n",
    "\n",
    "    # Lista com os caminhos das imagens (batch with 128 samples)\n",
    "    path_test_batch = list(path_list)\n",
    "\n",
    "    # Consolidate das listas de predicao e resposta\n",
    "    for i in range(0, len(pred_test_batch)):\n",
    "        true_test_list.append(true_test_batch[i])\n",
    "        pred_test_list.append(pred_test_batch[i])\n",
    "        path_test_list.append(path_test_batch[i])\n",
    "\n",
    "        prob_test_list.append(prob_test_batch[i])\n",
    "\n",
    "# Calculo o tempo final \n",
    "finish_test = time.time()\n",
    "\n",
    "# Calculo do tempo total de teste\n",
    "time_total_test = finish_test - time_test_start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resposta_val\n",
    "true_val_list = []\n",
    "pred_val_list = []\n",
    "path_val_list = []\n",
    "\n",
    "prob_val_list = []\n",
    "\n",
    "# Itera sob o dataloader_val\n",
    "# --------------------------\n",
    "for i, (img_list, labelList, path_list) in enumerate(dataloader_val):\n",
    "\n",
    "    if DEVICE.type == 'cuda':\n",
    "        # Cuda extension\n",
    "        img_list = img_list.to(DEVICE)\n",
    "        labelList = labelList.to(DEVICE)\n",
    "\n",
    "    # Nao atualizar o gradiente\n",
    "    torch.set_grad_enabled(False) \n",
    "\n",
    "    # >>>>> FORWARD\n",
    "    outputs = model(img_list)\n",
    "\n",
    "    if num_classes == 2 and args.bce:\n",
    "        # Calculate probabilities\n",
    "        # https://discuss.pytorch.org/t/bceloss-vs-bcewithlogitsloss/33586/27\n",
    "        outputs_prob = torch.sigmoid(outputs) \n",
    "        preds = (outputs_prob > 0.5).float().squeeze()\n",
    "\n",
    "        prob_val_batch = np.asarray(outputs_prob.cpu())\n",
    "\n",
    "        prob_val_batch = np.c_[1. - prob_val_batch, prob_val_batch]\n",
    "\n",
    "    else:\n",
    "        ### _, preds = torch.max(output, 1)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "\n",
    "        # https://discuss.pytorch.org/t/obtain-probabilities-from-cross-entropy-loss/157259\n",
    "        outputs_prob = nn.functional.softmax(outputs, dim=1)\n",
    "\n",
    "        prob_val_batch = np.asarray(outputs_prob.cpu())\n",
    "\n",
    "    # Obtém as classes reais (True) e classes preditas (pred) deste lote.\n",
    "    if DEVICE.type == 'cuda':\n",
    "        true_val_batch = np.asarray(labelList.cpu())\n",
    "        pred_val_batch = np.asarray(preds.cpu())\n",
    "    else:\n",
    "        true_val_batch = np.asarray(labelList)\n",
    "        pred_val_batch = np.asarray(preds)\n",
    "        \n",
    "    # Obtém os caminhos das imagens deste lote\n",
    "    path_val_batch = list(path_list)\n",
    "\n",
    "    # Itera sob cada item predito. (Esse FOR tem tamanho do batch_size)\n",
    "    for i in range(0, len(pred_val_batch)):\n",
    "        true_val_list.append(true_val_batch[i])\n",
    "        pred_val_list.append(pred_val_batch[i])\n",
    "        path_val_list.append(path_val_batch[i])\n",
    "\n",
    "        prob_val_list.append(prob_val_batch[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion matrix and classification reports (Scikit-learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST SET\n",
    "# -------------------------------------------------------------------------\n",
    "\n",
    "# Confusion matrix\n",
    "conf_mat_test = metrics.confusion_matrix(true_test_list, pred_test_list)\n",
    "# Classification report - Scikit-learn\n",
    "class_rep_test = metrics.classification_report(true_test_list, pred_test_list, \n",
    "                                               target_names=class_names, digits=4)\n",
    "# Accuracy\n",
    "acc_test = metrics.accuracy_score(true_test_list, pred_test_list)\n",
    "\n",
    "class_rep_path = os.path.join(EXP_PATH, 'classification_report_test.txt')\n",
    "file_rep = open(class_rep_path, 'w')\n",
    "\n",
    "file_rep.write('\\n\\nTEST SET:')\n",
    "file_rep.write('\\n---------------')\n",
    "file_rep.write('\\nConfusion matrix:\\n')\n",
    "file_rep.write(str(conf_mat_test))\n",
    "file_rep.write('\\n')\n",
    "file_rep.write('\\nClassification report:\\n')\n",
    "file_rep.write(class_rep_test)\n",
    "file_rep.write('\\n')\n",
    "file_rep.write('\\nAccuracy:\\t' + str(acc_test))\n",
    "\n",
    "file_rep.close()\n",
    "\n",
    "# Ploting the confusion matrix\n",
    "fig_obj = plt.figure()\n",
    "metrics.ConfusionMatrixDisplay(conf_mat_test).plot()\n",
    "# Save figure in disk\n",
    "plt.savefig(os.path.join(EXP_PATH, 'conf_mat_test.png')) \n",
    "plt.savefig(os.path.join(EXP_PATH, 'conf_mat_test.pdf')) \n",
    "with open(os.path.join(EXP_PATH, 'conf_mat_test.pickle'),'wb') as file:\n",
    "    pickle.dump(fig_obj, file)\n",
    "\n",
    "print('TEST. Acc.: {:.4f}'.format(acc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VALIDATION SET\n",
    "# -------------------------------------------------------------------------\n",
    "# Confusion matrix\n",
    "conf_mat_val = metrics.confusion_matrix(true_val_list, pred_val_list)\n",
    "# Classification report - Scikit-learn\n",
    "class_rep_val = metrics.classification_report(true_val_list, pred_val_list, \n",
    "                                              target_names=class_names, digits=4)\n",
    "# Accuracy\n",
    "acc_val = metrics.accuracy_score(true_val_list, pred_val_list)\n",
    "\n",
    "class_rep_path = os.path.join(EXP_PATH, 'classification_report_val.txt')\n",
    "file_rep = open(class_rep_path, 'w')\n",
    "\n",
    "file_rep.write('VALIDATION SET:')\n",
    "file_rep.write('\\n---------------')\n",
    "file_rep.write('\\nConfusion matrix:\\n')\n",
    "file_rep.write(str(conf_mat_val))\n",
    "file_rep.write('\\n')\n",
    "file_rep.write('\\nClassification report:\\n')\n",
    "file_rep.write(class_rep_val)\n",
    "file_rep.write('\\n')\n",
    "file_rep.write('\\nAccuracy:\\t' + str(acc_val))\n",
    "\n",
    "file_rep.close()\n",
    "\n",
    "# Ploting the confusion matrix\n",
    "fig_obj = plt.figure()\n",
    "metrics.ConfusionMatrixDisplay(conf_mat_val).plot()\n",
    "# Save figure in disk\n",
    "plt.savefig(os.path.join(EXP_PATH, 'conf_mat_val.png')) \n",
    "plt.savefig(os.path.join(EXP_PATH, 'conf_mat_val.pdf')) \n",
    "with open(os.path.join(EXP_PATH, 'conf_mat_val.pickle'),'wb') as file:\n",
    "    pickle.dump(fig_obj, file)\n",
    "\n",
    "print('VAL. Acc.: {:.4f}'.format(acc_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.wandb:   \n",
    "        wandb.log({'eval_val_acc': acc_val, 'eval_test_acc': acc_test, 'best_epoch': early_stopping.best_epoch})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usa o método __get_item__ da classe ... extendida da classe Dataset\n",
    "\n",
    "# Conjunto de validação\n",
    "file_details_path = os.path.join(EXP_PATH, 'classification_details_val.csv')\n",
    "file_details = open(file_details_path, 'w')\n",
    "\n",
    "file_details.write('VALIDATION SET')\n",
    "file_details.write('\\n#\\tFile path\\tTarget\\tPrediction')\n",
    "\n",
    "for class_name in class_names:\n",
    "    file_details.write('\\t' + str(class_name))\n",
    "\n",
    "for i, (target, pred, probs) in enumerate(zip(true_val_list, pred_val_list, prob_val_list)):\n",
    "    image_name = str(path_val_list[i])\n",
    "    file_details.write('\\n' + str(i) + '\\t' + image_name + '\\t' + str(target) + '\\t' + str(pred))\n",
    "\n",
    "    for prob in probs:\n",
    "        file_details.write('\\t' + str(prob))\n",
    "\n",
    "file_details.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conjunto de testes\n",
    "file_details_path = os.path.join(EXP_PATH, 'classification_details_test.csv')\n",
    "file_details = open(file_details_path, 'w')\n",
    "\n",
    "file_details.write('TEST SET')\n",
    "file_details.write('\\n#\\tFile path\\tTarget\\tPrediction')\n",
    "\n",
    "for class_name in class_names:\n",
    "    file_details.write('\\t' + str(class_name))\n",
    "\n",
    "for i, (target, pred, probs) in enumerate(zip(true_test_list, pred_test_list, prob_test_list)):\n",
    "    image_name = str(path_test_list[i])\n",
    "    file_details.write('\\n' + str(i) + '\\t' + image_name + '\\t' + str(target) + '\\t' + str(pred))\n",
    "\n",
    "    for prob in probs:\n",
    "        file_details.write('\\t' + str(prob))\n",
    "\n",
    "file_details.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter optimization report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.optim != 'none':\n",
    "    print('\\n>> Relatório da otimização de hiperparametros...')\n",
    "    # O nome de um arquivo CSV. Irá armazenar todos os losses e acuracias.\n",
    "    hp_filename = os.path.join(EXP_PATH_MAIN, '(' + args.ds + ')-' + args.arch + '-' + args.optim + '.csv')\n",
    "else:\n",
    "    print('\\n>> Relatório do conjunto de experimentos...')\n",
    "    # O nome de um arquivo CSV. Irá armazenar todos os losses e acuracias.\n",
    "    hp_filename = os.path.join(EXP_PATH_MAIN, '(' + args.ds + ')-' + args.optim + '.csv')\n",
    "\n",
    "\n",
    "if args.ec == 0:\n",
    "    # Cria o arquivo CSV\n",
    "    hp_file = open(hp_filename, 'w')\n",
    "\n",
    "    # Criar cabeçalho\n",
    "    header = '#\\tDS\\tARCH\\tHP\\tFT\\tBS\\tLR\\tMM\\tSS\\tEP\\tES\\tACC_VAL\\tACC_TEST\\tACC_TRAIN(*)\\tACC_VAL(*)\\tTIME\\n'\n",
    "    hp_file.write(header)\n",
    "\n",
    "else:\n",
    "    # Cria o arquivo CSV\n",
    "    hp_file = open(hp_filename, 'a')\n",
    "\n",
    "if args.es:\n",
    "    info = f'{args.ec}\\t{args.ds}\\t{args.arch}\\t{args.optim}\\t{args.ft}\\t{args.bs}\\t{args.lr}\\t{args.mm}\\t{args.ss}\\t{args.ep}\\t{early_stopping.best_epoch}\\t{acc_val}\\t{acc_test}\\t{train_acc_list[-1]}\\t{val_acc_list[-1]}\\t{str(datetime.timedelta(seconds=time_total_train))}\\n'\n",
    "else:\n",
    "    info = f'{args.ec}\\t{args.ds}\\t{args.arch}\\t{args.optim}\\t{args.ft}\\t{args.bs}\\t{args.lr}\\t{args.mm}\\t{args.ss}\\t{args.ep}\\t{args.ep - 1}\\t{acc_val}\\t{acc_test}\\t{train_acc_list[-1]}\\t{val_acc_list[-1]}\\t{str(datetime.timedelta(seconds=time_total_train))}\\n'\n",
    "\n",
    "hp_file.write(info)\n",
    "\n",
    "hp_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Done!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()\n",
    "\n",
    "# Se o arquivo \"done.txt\" estiver na pasta, o experimento foi finalizado com sucesso!\n",
    "done_file = open(os.path.join(EXP_PATH, 'done.txt'), 'w')\n",
    "done_file.close()\n",
    "\n",
    "print('\\nDone!\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References \n",
    "---\n",
    "\n",
    "* https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n",
    "* Finetuning Torchvision Models\n",
    "    * https://colab.research.google.com/github/pytorch/tutorials/blob/gh-pages/_downloads/finetuning_torchvision_models_tutorial.ipynb \n",
    "* https://github.com/Spandan-Madan/Pytorch_fine_tuning_Tutorial\n",
    "* https://huggingface.co/docs/transformers/training\n",
    "* torchvision models\n",
    "    * https://pytorch.org/vision/stable/models.html\n",
    "* TIMM Models\n",
    "    * https://paperswithcode.com/lib/timm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-CNNPestes-py11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
